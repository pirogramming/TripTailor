import os
import json
import numpy as np
from typing import Dict, List, Optional, Tuple
import faiss
from datetime import datetime
import requests
from decouple import config

class ReviewPipelineService:
    
    def __init__(self):
        self.faiss_index_path = "triptailor_cosine_v2.index"
        self.metadata_path = "triptailor_full_metadata.csv"
        self.training_data_path = "training_data/"
        
        # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
        self.faiss_index = self._load_faiss_index()
        self.metadata = self._load_metadata()
    
    def _load_faiss_index(self):
        """FAISS ì¸ë±ìŠ¤ ë¡œë“œ"""
        try:
            if os.path.exists(self.faiss_index_path):
                return faiss.read_index(self.faiss_index_path)
            else:
                print(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.faiss_index_path}")
                return None
        except Exception as e:
            print(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def _load_metadata(self):
        """ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        try:
            if os.path.exists(self.metadata_path):
                import pandas as pd
                return pd.read_csv(self.metadata_path)
            else:
                print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.metadata_path}")
                return None
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def clova_summarize(self, content: str) -> str:
        """
        ClovaXë¡œ ë¦¬ë·° ë‚´ìš© ìš”ì•½
        """
        try:
            # ClovaX API í‚¤ ê°€ì ¸ì˜¤ê¸°
            clova_api_key = config('CLOVA_API_KEY', default=None)
            clova_api_url = config('CLOVA_API_URL', default=None)
            
            if not clova_api_key or not clova_api_url:
                print("ClovaX API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ìš”ì•½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ë”ë¯¸ ìš”ì•½ ë¡œì§
                if len(content) > 100:
                    return content[:100] + "..."
                return content
            
            # ClovaX API ìš”ì²­
            headers = {
                'Content-Type': 'application/json',
                'X-NCP-APIGW-API-KEY-ID': clova_api_key,
                'X-NCP-APIGW-API-KEY': clova_api_key
            }
            
            # ìš”ì•½ ìš”ì²­ ë°ì´í„°
            data = {
                "text": content,
                "max_tokens": 100,
                "temperature": 0.3,
                "top_p": 0.8
            }
            
            response = requests.post(clova_api_url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                summary = result.get('summary', '')
                if summary:
                    return summary
                else:
                    print("ClovaX API ì‘ë‹µì— ìš”ì•½ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return self._fallback_summarize(content)
            else:
                print(f"ClovaX API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return self._fallback_summarize(content)
                
        except Exception as e:
            print(f"ClovaX ìš”ì•½ ì‹¤íŒ¨: {e}")
            return self._fallback_summarize(content)
    
    def _fallback_summarize(self, content: str) -> str:
        """
        ClovaX API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ëŒ€ì²´ ìš”ì•½ ë¡œì§
        """
        if len(content) > 100:
            return content[:100] + "..."
        return content
    
    def clova_embed(self, content: str) -> np.ndarray:
        """
        Clova Embeddingìœ¼ë¡œ ì„ë² ë”© ìƒì„±
        """
        try:
            # Clova Embedding API í‚¤ ê°€ì ¸ì˜¤ê¸°
            clova_embed_api_key = config('CLOVA_EMBED_API_KEY', default=None)
            clova_embed_api_url = config('CLOVA_EMBED_API_URL', default=None)
            
            if not clova_embed_api_key or not clova_embed_api_url:
                print("Clova Embedding API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ì„ë² ë”©ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                # ë”ë¯¸ ì„ë² ë”© ìƒì„±
                embedding_dim = 768
                return np.random.randn(embedding_dim).astype('float32')
            
            # Clova Embedding API ìš”ì²­
            headers = {
                'Content-Type': 'application/json',
                'X-NCP-APIGW-API-KEY-ID': clova_embed_api_key,
                'X-NCP-APIGW-API-KEY': clova_embed_api_key
            }
            
            # ì„ë² ë”© ìš”ì²­ ë°ì´í„°
            data = {
                "text": content,
                "model": "clova-embedding-v1"  # ë˜ëŠ” ì‹¤ì œ ëª¨ë¸ëª…
            }
            
            response = requests.post(clova_embed_api_url, headers=headers, json=data, timeout=30)
            
            if response.status_code == 200:
                result = response.json()
                embedding = result.get('embedding', [])
                if embedding:
                    return np.array(embedding, dtype='float32')
                else:
                    print("Clova Embedding API ì‘ë‹µì— ì„ë² ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return self._fallback_embed(content)
            else:
                print(f"Clova Embedding API ìš”ì²­ ì‹¤íŒ¨: {response.status_code} - {response.text}")
                return self._fallback_embed(content)
                
        except Exception as e:
            print(f"Clova Embedding ì‹¤íŒ¨: {e}")
            return self._fallback_embed(content)
    
    def _fallback_embed(self, content: str) -> np.ndarray:
        """
        Clova Embedding API ì‹¤íŒ¨ ì‹œ ì‚¬ìš©í•  ëŒ€ì²´ ì„ë² ë”© ë¡œì§
        """
        embedding_dim = 768
        return np.random.randn(embedding_dim).astype('float32')
    
    def should_update(self, review, new_summary: str) -> bool:
        """
        íŒ€ í•©ì˜ëœ ì—…ë°ì´íŠ¸ íŒë‹¨ ê¸°ì¤€:
        - í›„ê¸° ìš”ì•½ë¬¸: cosine similarity < 0.9
        - íƒœê·¸: ì§‘í•©(set) ë‹¤ë¦„
        """
        try:
            # 1. í›„ê¸° ìš”ì•½ë¬¸ ë¹„êµ (cosine similarity < 0.9)
            old_summary = review.summary
            summary_similarity = self._calculate_cosine_similarity(old_summary, new_summary)
            
            # 2. íƒœê·¸ ë¹„êµ (ì§‘í•© ë‹¤ë¦„)
            old_tags = self._extract_tags(old_summary)
            new_tags = self._extract_tags(new_summary)
            tags_different = old_tags != new_tags
            
            # ì—…ë°ì´íŠ¸ ì¡°ê±´: ìš”ì•½ë¬¸ ìœ ì‚¬ë„ < 0.9 ë˜ëŠ” íƒœê·¸ê°€ ë‹¤ë¦„
            should_update = summary_similarity < 0.9 or tags_different
            
            print(f"ì—…ë°ì´íŠ¸ íŒë‹¨:")
            print(f"  - ìš”ì•½ë¬¸ ìœ ì‚¬ë„: {summary_similarity:.3f} (ì„ê³„ê°’: 0.9)")
            print(f"  - íƒœê·¸ ë‹¤ë¦„: {tags_different}")
            print(f"  - ì—…ë°ì´íŠ¸ í•„ìš”: {should_update}")
            
            return should_update
            
        except Exception as e:
            print(f"ì—…ë°ì´íŠ¸ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return True  # ì˜¤ë¥˜ ì‹œ ì—…ë°ì´íŠ¸ ì§„í–‰
    
    def _calculate_cosine_similarity(self, text1: str, text2: str) -> float:
        """
        ë‘ í…ìŠ¤íŠ¸ ê°„ì˜ cosine similarity ê³„ì‚°
        """
        try:
            # ê°„ë‹¨í•œ cosine similarity ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)
            words1 = text1.lower().split()
            words2 = text2.lower().split()
            
            # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚°
            from collections import Counter
            freq1 = Counter(words1)
            freq2 = Counter(words2)
            
            # ëª¨ë“  ë‹¨ì–´ ì§‘í•©
            all_words = set(freq1.keys()) | set(freq2.keys())
            
            if not all_words:
                return 1.0
            
            # ë²¡í„° ìƒì„±
            vec1 = [freq1.get(word, 0) for word in all_words]
            vec2 = [freq2.get(word, 0) for word in all_words]
            
            # cosine similarity ê³„ì‚°
            dot_product = sum(a * b for a, b in zip(vec1, vec2))
            norm1 = sum(a * a for a in vec1) ** 0.5
            norm2 = sum(b * b for b in vec2) ** 0.5
            
            if norm1 == 0 or norm2 == 0:
                return 0.0
            
            return dot_product / (norm1 * norm2)
            
        except Exception as e:
            print(f"Cosine similarity ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def _extract_tags(self, text: str) -> set:
        """
        í…ìŠ¤íŠ¸ì—ì„œ íƒœê·¸ ì¶”ì¶œ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ)
        """
        try:
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš©)
            import re
            
            # íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì†Œë¬¸ì ë³€í™˜
            clean_text = re.sub(r'[^\w\s]', '', text.lower())
            
            # ë¶ˆìš©ì–´ ì œê±°
            stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'her', 'its', 'our', 'their', 'mine', 'yours', 'his', 'hers', 'ours', 'theirs'}
            
            words = clean_text.split()
            keywords = [word for word in words if word not in stop_words and len(word) > 2]
            
            # ìƒìœ„ í‚¤ì›Œë“œë§Œ íƒœê·¸ë¡œ ì‚¬ìš©
            from collections import Counter
            word_freq = Counter(keywords)
            top_tags = {word for word, freq in word_freq.most_common(5)}
            
            return top_tags
            
        except Exception as e:
            print(f"íƒœê·¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return set()
    
    def update_faiss_db(self, review, embedding: np.ndarray, summary: str):
        """
        FAISS DBì™€ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
        """
        try:
            if self.faiss_index is None:
                print("FAISS ì¸ë±ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return
            
            # ì„ë² ë”©ì„ FAISS ì¸ë±ìŠ¤ì— ì¶”ê°€
            embedding_reshaped = embedding.reshape(1, -1)
            self.faiss_index.add(embedding_reshaped)
            
            # ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
            new_metadata = {
                'id': review.id,
                'user_id': review.user.id,
                'route_id': review.route.id,
                'rating': float(review.rating),
                'summary': summary,
                'content': review.content,
                'created_at': review.created_at.isoformat(),
                'updated_at': datetime.now().isoformat()
            }
            
            # ë©”íƒ€ë°ì´í„° ì €ì¥
            self._save_metadata(new_metadata)
            
            # FAISS ì¸ë±ìŠ¤ ì €ì¥
            faiss.write_index(self.faiss_index, self.faiss_index_path)
            
            print(f"FAISS DB ì—…ë°ì´íŠ¸ ì™„ë£Œ: ë¦¬ë·° ID {review.id}")
            
        except Exception as e:
            print(f"FAISS DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def _save_metadata(self, metadata: Dict):
        """
        ë©”íƒ€ë°ì´í„° ì €ì¥
        """
        try:
            import pandas as pd
            
            # ê¸°ì¡´ ë©”íƒ€ë°ì´í„°ì— ìƒˆ ë°ì´í„° ì¶”ê°€
            if self.metadata is not None:
                new_df = pd.DataFrame([metadata])
                self.metadata = pd.concat([self.metadata, new_df], ignore_index=True)
            else:
                self.metadata = pd.DataFrame([metadata])
            
            # CSV íŒŒì¼ë¡œ ì €ì¥
            self.metadata.to_csv(self.metadata_path, index=False)
            
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def save_training_data(self, review, summary: str):
        """
        Fine-tuningìš© í•™ìŠµ ë°ì´í„° ì €ì¥ (ì •í•©ì„± íŒë‹¨ í›„)
        """
        try:
            # ì •í•©ì„± íŒë‹¨
            if not self._validate_training_data(review, summary):
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨ - í•™ìŠµ ë°ì´í„° ì €ì¥ ê±´ë„ˆëœ€")
                return
            
            # í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(self.training_data_path, exist_ok=True)
            
            # í•™ìŠµ ë°ì´í„° êµ¬ì„±
            training_data = {
                'id': review.id,
                'input': review.content,
                'output': summary,
                'rating': float(review.rating),
                'route_id': review.route.id,
                'created_at': review.created_at.isoformat(),
                'validation_score': self._calculate_validation_score(review, summary)
            }
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            filename = f"training_data_{review.id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(self.training_data_path, filename)
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(training_data, f, ensure_ascii=False, indent=2)
            
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
            
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def _validate_training_data(self, review, summary: str) -> bool:
        """
        í•™ìŠµ ë°ì´í„° ì •í•©ì„± íŒë‹¨
        """
        try:
            # 1. ë‚´ìš© ê¸¸ì´ ê²€ì¦
            if len(review.content) < 10 or len(summary) < 5:
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ")
                return False
            
            # 2. ìš”ì•½ë¬¸ í’ˆì§ˆ ê²€ì¦ (ì›ë³¸ê³¼ ìš”ì•½ë¬¸ì˜ ìœ ì‚¬ë„ê°€ ì ì ˆí•œì§€)
            similarity = self._calculate_cosine_similarity(review.content, summary)
            if similarity > 0.95:  # ë„ˆë¬´ ìœ ì‚¬í•˜ë©´ ìš”ì•½ì´ ì œëŒ€ë¡œ ì•ˆëœ ê²ƒ
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ë¬¸ì´ ì›ë³¸ê³¼ ë„ˆë¬´ ìœ ì‚¬í•¨ (ìœ ì‚¬ë„: {similarity:.3f})")
                return False
            
            if similarity < 0.1:  # ë„ˆë¬´ ë‹¤ë¥´ë©´ ìš”ì•½ì´ ì˜ëª»ëœ ê²ƒ
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ë¬¸ì´ ì›ë³¸ê³¼ ë„ˆë¬´ ë‹¤ë¦„ (ìœ ì‚¬ë„: {similarity:.3f})")
                return False
            
            # 3. í‰ì  ê²€ì¦
            if not (0.0 <= float(review.rating) <= 5.0):
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: í‰ì ì´ ë²”ìœ„ë¥¼ ë²—ì–´ë‚¨")
                return False
            
            # 4. í‚¤ì›Œë“œ ì¤‘ë³µ ê²€ì¦
            content_keywords = self._extract_tags(review.content)
            summary_keywords = self._extract_tags(summary)
            keyword_overlap = len(content_keywords & summary_keywords) / len(content_keywords | summary_keywords) if content_keywords | summary_keywords else 0
            
            if keyword_overlap < 0.1:  # í‚¤ì›Œë“œ ì¤‘ë³µì´ ë„ˆë¬´ ì ìœ¼ë©´ ìš”ì•½ì´ ì˜ëª»ëœ ê²ƒ
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: í‚¤ì›Œë“œ ì¤‘ë³µì´ ë„ˆë¬´ ì ìŒ (ì¤‘ë³µë¥ : {keyword_overlap:.3f})")
                return False
            
            print(f"ì •í•©ì„± ê²€ì¦ í†µê³¼:")
            print(f"  - ë‚´ìš© ê¸¸ì´: OK")
            print(f"  - ìš”ì•½ë¬¸ ìœ ì‚¬ë„: {similarity:.3f} (ì ì ˆí•¨)")
            print(f"  - í‰ì : {review.rating} (OK)")
            print(f"  - í‚¤ì›Œë“œ ì¤‘ë³µë¥ : {keyword_overlap:.3f} (ì ì ˆí•¨)")
            
            return True
            
        except Exception as e:
            print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _calculate_validation_score(self, review, summary: str) -> float:
        """
        í•™ìŠµ ë°ì´í„° ê²€ì¦ ì ìˆ˜ ê³„ì‚°
        """
        try:
            # ì—¬ëŸ¬ ì§€í‘œë¥¼ ì¢…í•©í•œ ê²€ì¦ ì ìˆ˜
            scores = []
            
            # 1. ìš”ì•½ë¬¸ í’ˆì§ˆ ì ìˆ˜
            similarity = self._calculate_cosine_similarity(review.content, summary)
            summary_score = max(0, 1 - abs(similarity - 0.7))  # 0.7 ê·¼ì²˜ê°€ ìµœì 
            scores.append(summary_score)
            
            # 2. í‚¤ì›Œë“œ ì¤‘ë³µ ì ìˆ˜
            content_keywords = self._extract_tags(review.content)
            summary_keywords = self._extract_tags(summary)
            keyword_overlap = len(content_keywords & summary_keywords) / len(content_keywords | summary_keywords) if content_keywords | summary_keywords else 0
            scores.append(keyword_overlap)
            
            # 3. ë‚´ìš© ê¸¸ì´ ì ìˆ˜
            content_length_score = min(1.0, len(review.content) / 100)  # 100ì ì´ìƒì´ë©´ ë§Œì 
            summary_length_score = min(1.0, len(summary) / 50)  # 50ì ì´ìƒì´ë©´ ë§Œì 
            scores.append((content_length_score + summary_length_score) / 2)
            
            # í‰ê·  ì ìˆ˜ ë°˜í™˜
            return sum(scores) / len(scores)
            
        except Exception as e:
            print(f"ê²€ì¦ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return 0.0
    
    def process_review(self, review) -> bool:
        """
        ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰
        íŒ€ í•©ì˜ëœ íŒŒì´í”„ë¼ì¸ íë¦„:
        1. ClovaXë¡œ ìš”ì•½
        2. ê¸°ì¡´ summaryì™€ íƒœê·¸ ë¹„êµ
        3. ì¡°ê±´ ì¶©ì¡± ì‹œ ì—…ë°ì´íŠ¸ ì§„í–‰
        4. Clova Embeddingìœ¼ë¡œ ì„ë² ë”©
        5. FAISS DB + metadata ì €ì¥
        6. ì •í•©ì„± íŒë‹¨ í›„ fine-tuningìš© í•™ìŠµ ë°ì´í„° ì €ì¥
        """
        try:
            print(f"\nğŸ¤– ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì‹œì‘: ë¦¬ë·° ID {review.id}")
            print(f"ğŸ“ ì›ë³¸ ë‚´ìš©: {review.content[:100]}...")
            print(f"â­ í‰ì : {review.rating}")
            
            # 1. ClovaXë¡œ ìš”ì•½
            print(f"\n1ë‹¨ê³„: ClovaX ìš”ì•½ ì¤‘...")
            new_summary = self.clova_summarize(review.content)
            print(f"ìš”ì•½ ì™„ë£Œ: {new_summary}")
            
            # 2. ê¸°ì¡´ summaryì™€ íƒœê·¸ ë¹„êµ
            print(f"\n2ë‹¨ê³„: ì—…ë°ì´íŠ¸ í•„ìš”ì„± íŒë‹¨ ì¤‘...")
            if self.should_update(review, new_summary):
                print(f"ì—…ë°ì´íŠ¸ í•„ìš” - íŒŒì´í”„ë¼ì¸ ê³„ì† ì§„í–‰")
                
                # 3. Clova Embeddingìœ¼ë¡œ ì„ë² ë”©
                print(f"\n3ë‹¨ê³„: Clova Embedding ìƒì„± ì¤‘...")
                embedding = self.clova_embed(review.content)
                print(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding)})")
                
                # 4. FAISS DB + metadata ì €ì¥
                print(f"\n4ë‹¨ê³„: FAISS DB ì—…ë°ì´íŠ¸ ì¤‘...")
                self.update_faiss_db(review, embedding, new_summary)
                
                # 5. ì •í•©ì„± íŒë‹¨ í›„ fine-tuningìš© í•™ìŠµ ë°ì´í„° ì €ì¥
                print(f"\n5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì €ì¥ ì¤‘...")
                self.save_training_data(review, new_summary)
                
                print(f"\nğŸ‰ ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ë¦¬ë·° ID {review.id}")
                return True
            else:
                print(f"â­ï¸ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” - íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ")
                return False
                
        except Exception as e:
            print(f"âŒ ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False 