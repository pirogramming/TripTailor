import os
import json
import uuid
import numpy as np
from typing import Dict
import faiss
from datetime import datetime
import requests
from decouple import config

from django.core.management.base import BaseCommand
from django.conf import settings


def _get_base_dir() -> str:
    return str(getattr(settings, "BASE_DIR", os.getcwd()))


class ReviewPipelineService:
    def __init__(self):
        base_dir = _get_base_dir()
        self.faiss_index_path = os.path.join(base_dir, "triptailor_cosine_v2.index")
        self.metadata_path = os.path.join(base_dir, "triptailor_full_metadata.csv")
        self.training_data_path = os.path.join(base_dir, "training_data")

        # FAISS ì¸ë±ìŠ¤ / ë©”íƒ€ë°ì´í„° ë¡œë“œ
        self.faiss_index = self._load_faiss_index()
        self.metadata = self._load_metadata()

    # ---------------------------
    # Loaders & Utilities
    # ---------------------------
    def _load_faiss_index(self):
        try:
            if os.path.exists(self.faiss_index_path):
                return faiss.read_index(self.faiss_index_path)
            else:
                print(f"FAISS ì¸ë±ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.faiss_index_path}")
                return None
        except Exception as e:
            print(f"FAISS ì¸ë±ìŠ¤ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _load_metadata(self):
        try:
            if os.path.exists(self.metadata_path):
                import pandas as pd
                return pd.read_csv(self.metadata_path)
            else:
                print(f"ë©”íƒ€ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {self.metadata_path}")
                return None
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _index_dim(self) -> int:
        # ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ê·¸ ì°¨ì›, ì—†ìœ¼ë©´ í”„ë¡œì íŠ¸ ê¸°ë³¸ 1024(Clova v2 ê°€ì •)
        if self.faiss_index is not None:
            return int(self.faiss_index.d)
        return 1024

    # ---------------------------
    # Clova: Summarize
    # ---------------------------
    def clova_summarize(self, content: str) -> str:
        """
        ClovaX(HCX-005)ë¡œ í›„ê¸° ìš”ì•½. í‚¤ ì—†ê±°ë‚˜ ì‹¤íŒ¨ ì‹œ fallback.
        """
        try:
            api_key = config("CLOVASTUDIO_API_KEY", default=None)
            if not api_key:
                print("CLOVASTUDIO_API_KEY ë¯¸ì„¤ì • â†’ ë”ë¯¸ ìš”ì•½")
                return self._fallback_summarize(content)

            # LangChain ê²½ìœ  (í”„ë¡œì íŠ¸ì—ì„œ ì´ë¯¸ ì‚¬ìš© ì¤‘)
            from langchain_naver import ChatClovaX
            from langchain_core.prompts import PromptTemplate

            if api_key:
                   os.environ["CLOVASTUDIO_API_KEY"] = api_key 

            llm = ChatClovaX(model="HCX-005", temperature=0 )
            prompt = PromptTemplate.from_template("ë‹¤ìŒ í›„ê¸°ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ê°„ê²° ìš”ì•½:\n{review}")
            out = (prompt | llm).invoke({"review": content})
            text = getattr(out, "content", str(out)).strip()
            return text or self._fallback_summarize(content)
        except Exception as e:
            print(f"ClovaX ìš”ì•½ ì‹¤íŒ¨: {e}")
            return self._fallback_summarize(content)

    def _fallback_summarize(self, content: str) -> str:
        return (content[:100] + "...") if len(content) > 100 else content

    # ---------------------------
    # Clova: Embedding
    # ---------------------------
    def clova_embed(self, content: str) -> np.ndarray:
        """
        Clova Embedding v2 í˜¸ì¶œ. ì‹¤íŒ¨ ì‹œ ì¸ë±ìŠ¤ ì°¨ì›ì— ë§ì¶˜ ë‚œìˆ˜ ë”ë¯¸.
        """
        try:
            api_key = config("CLOVASTUDIO_API_KEY", default=None)
            url = config(
                "CLOVA_EMBED_API_URL",
                default="https://clovastudio.stream.ntruss.com/v1/api-tools/embedding/v2",
            )
            if not api_key:
                print("CLOVASTUDIO_API_KEY ë¯¸ì„¤ì • â†’ ë”ë¯¸ ì„ë² ë”©")
                return self._fallback_embed(content)

            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
                "X-NCP-CLOVASTUDIO-REQUEST-ID": str(uuid.uuid4()),
            }
            payload = {"text": content}
            r = requests.post(url, headers=headers, json=payload, timeout=30)
            r.raise_for_status()
            vec = r.json()["result"]["embedding"]
            emb = np.array(vec, dtype="float32")

            # ì¸ë±ìŠ¤ ì°¨ì›ê³¼ ë¶ˆì¼ì¹˜ ì‹œ íŒ¨ë”©/ì ˆë‹¨
            dim = self._index_dim()
            if emb.shape[0] != dim:
                if emb.shape[0] > dim:
                    emb = emb[:dim]
                else:
                    emb = np.pad(emb, (0, dim - emb.shape[0]))
            return emb
        except Exception as e:
            print(f"Clova Embedding ì‹¤íŒ¨: {e}")
            return self._fallback_embed(content)

    def _fallback_embed(self, content: str) -> np.ndarray:
        dim = self._index_dim()
        return np.random.randn(dim).astype("float32")

    # ---------------------------
    # Update Decision
    # ---------------------------
    def should_update(self, review, new_summary: str) -> bool:
        """
        ì—…ë°ì´íŠ¸ ê¸°ì¤€:
        - ìš”ì•½ë¬¸ cosine similarity < 0.9
        - íƒœê·¸ ì§‘í•© ë³€í™”
        """
        try:
            old_summary = getattr(review, "summary", "") or ""
            summary_similarity = self._calculate_cosine_similarity(old_summary, new_summary)

            old_tags = self._extract_tags(old_summary)
            new_tags = self._extract_tags(new_summary)
            tags_different = old_tags != new_tags

            should_update = (summary_similarity < 0.9) or tags_different

            print("ì—…ë°ì´íŠ¸ íŒë‹¨:")
            print(f"  - ìš”ì•½ë¬¸ ìœ ì‚¬ë„: {summary_similarity:.3f} (ì„ê³„ê°’: 0.9)")
            print(f"  - íƒœê·¸ ë‹¤ë¦„: {tags_different}")
            print(f"  - ì—…ë°ì´íŠ¸ í•„ìš”: {should_update}")
            return should_update
        except Exception as e:
            print(f"ì—…ë°ì´íŠ¸ íŒë‹¨ ì‹¤íŒ¨: {e}")
            return True  # ë³´ìˆ˜ì ìœ¼ë¡œ ì§„í–‰

    def _calculate_cosine_similarity(self, text1: str, text2: str) -> float:
        try:
            words1 = (text1 or "").lower().split()
            words2 = (text2 or "").lower().split()
            from collections import Counter
            freq1, freq2 = Counter(words1), Counter(words2)
            vocab = set(freq1) | set(freq2)
            if not vocab:
                return 1.0
            v1 = [freq1.get(w, 0) for w in vocab]
            v2 = [freq2.get(w, 0) for w in vocab]
            dot = sum(a * b for a, b in zip(v1, v2))
            n1 = sum(a * a for a in v1) ** 0.5
            n2 = sum(b * b for b in v2) ** 0.5
            if n1 == 0 or n2 == 0:
                return 0.0
            return dot / (n1 * n2)
        except Exception:
            return 0.0

    def _extract_tags(self, text: str) -> set:
        try:
            import re
            stop = {
                'the','a','an','and','or','but','in','on','at','to','for','of','with','by',
                'is','are','was','were','be','been','being','have','has','had','do','does',
                'did','will','would','could','should','may','might','must','can','this','that',
                'these','those','i','you','he','she','it','we','they','me','him','her','us',
                'them','my','your','his','its','our','their','mine','yours','hers','ours','theirs'
            }
            clean = re.sub(r"[^\w\s]", "", (text or "").lower())
            words = [w for w in clean.split() if w not in stop and len(w) > 2]
            from collections import Counter
            return {w for w, _ in Counter(words).most_common(5)}
        except Exception:
            return set()

    # ---------------------------
    # FAISS / Metadata / Training
    # ---------------------------
    def update_faiss_db(self, review, embedding: np.ndarray, summary: str):
        try:
            # ì¸ë±ìŠ¤ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„± (ì½”ì‚¬ì¸ìš© Inner Product + L2 ì •ê·œí™”)
            if self.faiss_index is None:
                dim = embedding.shape[0]
                self.faiss_index = faiss.IndexFlatIP(dim)

            # ì½”ì‚¬ì¸ ê²€ìƒ‰ì„ ìœ„í•´ L2 ì •ê·œí™”
            norm = np.linalg.norm(embedding)
            if norm > 0:
                embedding = (embedding / norm).astype("float32")

            self.faiss_index.add(embedding.reshape(1, -1))

            new_metadata = {
                "id": getattr(review, "id", None),
                "user_id": getattr(getattr(review, "user", None), "id", None),
                "route_id": getattr(getattr(review, "route", None), "id", None),
                "rating": float(getattr(review, "rating", 0.0) or 0.0),
                "summary": summary,
                "content": getattr(review, "content", ""),
                "created_at": getattr(review, "created_at", datetime.now()).isoformat(),
                "updated_at": datetime.now().isoformat(),
            }
            self._save_metadata(new_metadata)
            faiss.write_index(self.faiss_index, self.faiss_index_path)
            print(f"FAISS DB ì—…ë°ì´íŠ¸ ì™„ë£Œ: ë¦¬ë·° ID {new_metadata['id']}")
        except Exception as e:
            print(f"FAISS DB ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")

    def _save_metadata(self, metadata: Dict):
        try:
            import pandas as pd
            if self.metadata is not None:
                self.metadata = pd.concat([self.metadata, pd.DataFrame([metadata])], ignore_index=True)
            else:
                self.metadata = pd.DataFrame([metadata])
            self.metadata.to_csv(self.metadata_path, index=False)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    def save_training_data(self, review, summary: str):
        try:
            if not self._validate_training_data(review, summary):
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨ - í•™ìŠµ ë°ì´í„° ì €ì¥ ìƒëµ")
                return

            os.makedirs(self.training_data_path, exist_ok=True)
            training = {
                "id": getattr(review, "id", None),
                "input": getattr(review, "content", ""),
                "output": summary,
                "rating": float(getattr(review, "rating", 0.0) or 0.0),
                "route_id": getattr(getattr(review, "route", None), "id", None),
                "user_id": getattr(getattr(review, "user", None), "id", None),
                "created_at": getattr(review, "created_at", datetime.now()).isoformat(),
                "validation_score": self._calculate_validation_score(review, summary),
            }
            filename = f"training_data_{training['id']}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(self.training_data_path, filename)
            with open(filepath, "w", encoding="utf-8") as f:
                json.dump(training, f, ensure_ascii=False, indent=2)
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {filepath}")
        except Exception as e:
            print(f"í•™ìŠµ ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")

    def _validate_training_data(self, review, summary: str) -> bool:
        try:
            content = getattr(review, "content", "") or ""
            if len(content) < 10 or len(summary) < 5:
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŒ")
                return False
            sim = self._calculate_cosine_similarity(content, summary)
            if sim > 0.95:
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ì´ ì›ë¬¸ê³¼ ê³¼ë„í•˜ê²Œ ìœ ì‚¬ (ìœ ì‚¬ë„ {sim:.3f})")
                return False
            if sim < 0.1:
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: ìš”ì•½ì´ ì›ë¬¸ê³¼ ê³¼ë„í•˜ê²Œ ìƒì´ (ìœ ì‚¬ë„ {sim:.3f})")
                return False
            rating = float(getattr(review, "rating", 0.0) or 0.0)
            if not (0.0 <= rating <= 5.0):
                print("ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: í‰ì  ë²”ìœ„ ì˜¤ë¥˜")
                return False
            content_kw = self._extract_tags(content)
            summary_kw = self._extract_tags(summary)
            overlap = (len(content_kw & summary_kw) / len(content_kw | summary_kw)) if (content_kw | summary_kw) else 0
            if overlap < 0.1:
                print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: í‚¤ì›Œë“œ ì¤‘ë³µë¥  ë‚®ìŒ ({overlap:.3f})")
                return False

            print("ì •í•©ì„± ê²€ì¦ í†µê³¼:")
            print(f"  - ìš”ì•½ ìœ ì‚¬ë„: {sim:.3f}")
            print(f"  - í‰ì : {rating}")
            print(f"  - í‚¤ì›Œë“œ ì¤‘ë³µë¥ : {overlap:.3f}")
            return True
        except Exception as e:
            print(f"ì •í•©ì„± ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False

    def _calculate_validation_score(self, review, summary: str) -> float:
        try:
            content = getattr(review, "content", "") or ""
            sim = self._calculate_cosine_similarity(content, summary)
            score1 = max(0, 1 - abs(sim - 0.7))  # 0.7 ê·¼ì²˜ ìµœì 
            kw_c = self._extract_tags(content)
            kw_s = self._extract_tags(summary)
            overlap = (len(kw_c & kw_s) / len(kw_c | kw_s)) if (kw_c | kw_s) else 0
            score2 = overlap
            score3 = (min(1.0, len(content) / 100) + min(1.0, len(summary) / 50)) / 2
            return (score1 + score2 + score3) / 3
        except Exception:
            return 0.0

    # ---------------------------
    # Orchestrator
    # ---------------------------
    def process_review(self, review) -> bool:
        """
        1) ìš”ì•½ â†’ 2) ê¸°ì¡´ summary/íƒœê·¸ì™€ ë¹„êµ â†’ 3) í•„ìš” ì‹œ ì„ë² ë”© ìƒì„± â†’
        4) FAISS & ë©”íƒ€ë°ì´í„° ì €ì¥ â†’ 5) í•™ìŠµë°ì´í„° ì €ì¥
        """
        try:
            print(f"\nğŸ¤– ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì‹œì‘: ë¦¬ë·° ID {getattr(review, 'id', None)}")
            print(f"ğŸ“ ì›ë³¸ ë‚´ìš©: {getattr(review, 'content', '')[:100]}...")
            print(f"â­ í‰ì : {getattr(review, 'rating', None)}")

            print("\n1ë‹¨ê³„: ClovaX ìš”ì•½ ì¤‘...")
            new_summary = self.clova_summarize(getattr(review, "content", "") or "")
            print(f"ìš”ì•½ ì™„ë£Œ: {new_summary}")

            print("\n2ë‹¨ê³„: ì—…ë°ì´íŠ¸ í•„ìš”ì„± íŒë‹¨ ì¤‘...")
            if self.should_update(review, new_summary):
                print("ì—…ë°ì´íŠ¸ í•„ìš” - íŒŒì´í”„ë¼ì¸ ì§„í–‰")

                print("\n3ë‹¨ê³„: Clova Embedding ìƒì„± ì¤‘...")
                embedding = self.clova_embed(getattr(review, "content", "") or "")
                print(f"ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì°¨ì›: {len(embedding)})")

                print("\n4ë‹¨ê³„: FAISS DB ì—…ë°ì´íŠ¸ ì¤‘...")
                self.update_faiss_db(review, embedding, new_summary)

                print("\n5ë‹¨ê³„: í•™ìŠµ ë°ì´í„° ì €ì¥ ì¤‘...")
                self.save_training_data(review, new_summary)

                print(f"\nğŸ‰ ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: ë¦¬ë·° ID {getattr(review, 'id', None)}")
                return True
            else:
                print("â­ï¸ ì—…ë°ì´íŠ¸ ë¶ˆí•„ìš” - íŒŒì´í”„ë¼ì¸ ì¢…ë£Œ")
                return False
        except Exception as e:
            print(f"âŒ ë¦¬ë·° íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}")
            return False


# ============================
# Django Management Command
# ============================
class Command(BaseCommand):
    help = "TripTailor ë¦¬ë·° ë¹„êµ/ì„ë² ë”© íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"

    def add_arguments(self, parser):
        parser.add_argument("--review-id", type=int, help="íŠ¹ì • Review.idë§Œ ì²˜ë¦¬")
        parser.add_argument("--limit", type=int, help="ì „ì²´ ì‹¤í–‰ ì‹œ ê°œìˆ˜ ì œí•œ")
        parser.add_argument("--dummy", action="store_true", help="DB ì—†ì´ ë”ë¯¸ ì‹¤í–‰")

    def _import_review_model(self):
        # ì•± ê²½ë¡œ ìœ ì—° ì§€ì›: apps.reviews.models â†’ ì‹¤íŒ¨ ì‹œ reviews.models
        try:
            from apps.reviews.models import Review as _Review
            return _Review
        except Exception:
            from reviews.models import Review as _Review
            return _Review

    def handle(self, *args, **options):
        svc = ReviewPipelineService()

        if options.get("dummy"):
            self.stdout.write("ë”ë¯¸ ëª¨ë“œ ì‹¤í–‰")
            class DummyUser:
                def __init__(self, id): self.id = id
            class DummyRoute:
                def __init__(self, id): self.id = id
            class DummyReview:
                def __init__(self):
                    self.id = 999
                    self.user = DummyUser(1)
                    self.route = DummyRoute(None)
                    self.rating = 4.5
                    self.content = "ì‹œì„¤ì´ ê¹¨ë—í•˜ê³  ì¡°ìš©í•´ì„œ íë§í•˜ê¸° ì¢‹ì€ ê³³ì´ì—ˆì–´ìš”."
                    self.summary = "ì‹œì„¤ì´ ê¹¨ë—í•˜ê³  ì¡°ìš©í•¨"
                    self.created_at = datetime.now()
            review = DummyReview()
            svc.process_review(review)
            return

        Review = self._import_review_model()

        # íŠ¹ì • ë¦¬ë·° 1ê±´
        if options.get("review_id"):
            rid = options["review_id"]
            try:
                review = Review.objects.get(id=rid)
            except Review.DoesNotExist:
                self.stderr.write(f"âŒ ë¦¬ë·° {rid} ì—†ìŒ")
                return
            svc.process_review(review)
            return

        # ì „ì²´ ì‹¤í–‰ (ê¸°ë³¸)
        qs = Review.objects.all().order_by("-id")
        limit = options.get("limit")
        if limit:
            qs = qs[:limit]

        total = qs.count()
        self.stdout.write(f"ğŸ” ì´ {total}ê°œ ë¦¬ë·° ì²˜ë¦¬ ì‹œì‘â€¦")
        fail = 0
        for i, review in enumerate(qs, start=1):
            self.stdout.write(f"\n---- [{i}/{total}] Review ID={review.id} ----")
            ok = svc.process_review(review)
            if not ok:
                fail += 1
        self.stdout.write(f"\nâœ… ì „ì²´ ì²˜ë¦¬ ì™„ë£Œ: ì„±ê³µ {total - fail} / ì‹¤íŒ¨ {fail}")
