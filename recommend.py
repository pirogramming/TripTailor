import os
import json
import requests
import uuid
import numpy as np
import faiss
import pandas as pd
from typing import List, Dict, Tuple, Optional, TypedDict
from dotenv import load_dotenv
from dataclasses import dataclass
from collections import defaultdict
import math

from langchain_core.prompts import PromptTemplate
from langchain_naver import ChatClovaX

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì„¤ì •
llm = ChatClovaX(
    model="HCX-005",
    temperature=0,
)

# íƒœê·¸ ìë™ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
tag_extraction_prompt = PromptTemplate.from_template(
    """
    ë‹¤ìŒ ì‚¬ìš©ìì˜ ì—¬í–‰ ìš”ì²­ì—ì„œ ê´€ë ¨ íƒœê·¸ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
    
    ìš”ì²­: "{user_input}"
    
    ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ì—ì„œ ê´€ë ¨ íƒœê·¸ë¥¼ ì°¾ì•„ì£¼ì„¸ìš”:
    - ì§€ì—­: ì„œìš¸, ë¶€ì‚°, ì œì£¼ë„, ê°•ì›ë„ ë“±
    - í™œë™: ì‚°ì±…, ë“±ì‚°, ë§›ì§‘, ì¹´í˜, ë¬¸í™”ì‹œì„¤, ì‡¼í•‘, ë ˆí¬ì¸  ë“±
    - ë¶„ìœ„ê¸°: ì¡°ìš©í•œ, í™œê¸°ì°¬, íë§, ë¡œë§¨í‹±, ê°€ì¡±ì¹œí™”ì  ë“±
    - ê³„ì ˆ: ë´„, ì—¬ë¦„, ê°€ì„, ê²¨ìš¸
    - ì‹œê°„: ì•„ì¹¨, ì ì‹¬, ì €ë…, ì•¼ê²½ ë“±
    
    JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:
    {{
        "tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3"],
        "region": "ì§€ì—­ëª… ë˜ëŠ” ë¹ˆ ë¬¸ìì—´",
        "activity": "ì£¼ìš” í™œë™ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´"
    }}
    
    íƒœê·¸ëŠ” 3-8ê°œ ì •ë„ë¡œ ì¶”ì¶œí•˜ê³ , ì‚¬ìš©ìê°€ ëª…ì‹œí•˜ì§€ ì•Šì€ ê²ƒì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”.
    """
)

@dataclass
class SearchResult:
    place_id: int
    name: str
    address: str
    region: str
    overview: str
    tags: List[str]
    place_class: int
    lat: float
    lng: float
    vector_score: float
    tag_score: float
    popularity_score: float
    final_score: float
    reason: str = ""

class AdvancedRecommendationEngine:
    def __init__(self):
        # FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
        try:
            self.index = faiss.read_index("triptailor_cosine_v2.index")
            self.metadata = pd.read_csv("triptailor_full_metadata.csv").fillna("")
            print("Using real FAISS index and metadata")
        except:
            print("Warning: FAISS index or metadata not found. Using dummy data.")
            self.index = None
            # ë”ë¯¸ ë°ì´í„° ìƒì„±
            dummy_data = []
            for i in range(1, 101):  # 100ê°œì˜ ë”ë¯¸ ì¥ì†Œ ìƒì„±
                dummy_data.append({
                    'ëª…ì¹­': f'í…ŒìŠ¤íŠ¸ ì¥ì†Œ {i}',
                    'ì£¼ì†Œ': f'í…ŒìŠ¤íŠ¸ ì£¼ì†Œ {i}',
                    'ì§€ì—­': ['ì„œìš¸', 'ë¶€ì‚°', 'ì œì£¼', 'ê°•ì›', 'ê²½ê¸°'][i % 5],
                    'ê°œìš”': f'í…ŒìŠ¤íŠ¸ ì¥ì†Œ {i}ì˜ ìƒì„¸í•œ ì„¤ëª…ì…ë‹ˆë‹¤. ì´ ì¥ì†ŒëŠ” í…ŒìŠ¤íŠ¸ ëª©ì ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ê°€ìƒì˜ ì—¬í–‰ì§€ì…ë‹ˆë‹¤.',
                    'tag1': ['ìì—°', 'ë¬¸í™”', 'ë ˆí¬ì¸ ', 'ì‡¼í•‘', 'ë§›ì§‘'][i % 5],
                    'tag2': ['íë§', 'ê´€ê´‘', 'ë“±ì‚°', 'ì¹´í˜', 'ë¬¸í™”'][i % 5],
                    'tag3': ['ì‚°ì±…', 'ì—­ì‚¬', 'ë°”ë‹¤', 'íë§', 'ë§›ì§‘'][i % 5],
                    'place_class': (i % 4) + 1,
                    'lat': 37.5665 + (i * 0.001),
                    'lng': 126.9780 + (i * 0.001)
                })
            self.metadata = pd.DataFrame(dummy_data)
        
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        self.alpha = 0.7      # ë²¡í„° ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
        self.beta = 0.25      # íƒœê·¸ ë§¤ì¹­ ê°€ì¤‘ì¹˜
        self.gamma = 0.05     # ì¸ê¸°ë„ ê°€ì¤‘ì¹˜
        
        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„°
        self.initial_k = 200  # ì´ˆê¸° ë²¡í„° ê²€ìƒ‰ ê²°ê³¼ ìˆ˜
        self.max_k = 1000     # ìµœëŒ€ í™•ì¥ ê°€ëŠ¥í•œ K
        
    def get_clova_embedding(self, text: str) -> List[float]:
        """Clova Studio APIë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±"""
        api_key = os.getenv("CLOVASTUDIO_API_KEY")
        if not api_key:
            raise ValueError("CLOVASTUDIO_API_KEY not found")
            
        url = "https://clovastudio.stream.ntruss.com/v1/api-tools/embedding/v2"
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json",
            "X-NCP-CLOVASTUDIO-REQUEST-ID": str(uuid.uuid4())
        }
        response = requests.post(url, headers=headers, json={"text": text})
        response.raise_for_status()
        return response.json()["result"]["embedding"]
    
    def extract_tags_with_llm(self, user_input: str) -> Dict:
        """LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ì ì…ë ¥ì—ì„œ íƒœê·¸ ìë™ ì¶”ì¶œ"""
        try:
            prompt = tag_extraction_prompt.format(user_input=user_input)
            response = llm.invoke(prompt)
            response_text = getattr(response, "content", str(response))
            
            # JSON íŒŒì‹±
            start_idx = response_text.find('{')
            end_idx = response_text.rfind('}') + 1
            if start_idx != -1 and end_idx != -1:
                json_str = response_text[start_idx:end_idx]
                result = json.loads(json_str)
                return {
                    "tags": result.get("tags", []),
                    "region": result.get("region", ""),
                    "activity": result.get("activity", "")
                }
        except Exception as e:
            print(f"Tag extraction failed: {e}")
        
        return {"tags": [], "region": "", "activity": ""}
    
    def vector_search(self, query_embedding: List[float], k: int = 200) -> Tuple[np.ndarray, np.ndarray]:
        """FAISSë¥¼ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰"""
        if self.index is None:
            # ë”ë¯¸ ë°ì´í„°ë¥¼ ì‚¬ìš©í•  ë•ŒëŠ” ëœë¤ ê²°ê³¼ ë°˜í™˜
            total_items = len(self.metadata)
            k = min(k, total_items)
            indices = np.random.choice(total_items, k, replace=False)
            distances = np.random.random(k) * 0.1  # ì‘ì€ ê±°ë¦¬ê°’
            return distances, indices
            
        embedding = np.ascontiguousarray([query_embedding], dtype=np.float32)
        D, I = self.index.search(embedding, k)
        return D[0], I[0]  # ê±°ë¦¬, ì¸ë±ìŠ¤
    
    def calculate_tag_score(self, user_tags: List[str], place_tags: List[str]) -> float:
        """íƒœê·¸ ë§¤ì¹­ ì ìˆ˜ ê³„ì‚° (Jaccard ìœ ì‚¬ë„ ê¸°ë°˜)"""
        if not user_tags or not place_tags:
            return 0.0
            
        user_set = set(tag.lower().strip() for tag in user_tags if tag)
        place_set = set(tag.lower().strip() for tag in place_tags if tag)
        
        if not user_set or not place_set:
            return 0.0
            
        intersection = len(user_set & place_set)
        union = len(user_set | place_set)
        
        return intersection / union if union > 0 else 0.0
    
    def calculate_popularity_score(self, place_data: pd.Series) -> float:
        """ì¸ê¸°ë„ ì ìˆ˜ ê³„ì‚° (ì¢‹ì•„ìš” ìˆ˜, ë¦¬ë·° ìˆ˜ ë“± ê¸°ë°˜)"""
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ, ì‹¤ì œë¡œëŠ” PlaceLike, Review ëª¨ë¸ ë°ì´í„° ì‚¬ìš©
        return 0.5  # ê¸°ë³¸ê°’
    
    def apply_hard_filters(self, candidates: List[SearchResult], 
                          region: str = "", place_class: int = None) -> List[SearchResult]:
        """í•˜ë“œ í•„í„° ì ìš© (ì§€ì—­, ì¹´í…Œê³ ë¦¬ ë“±)"""
        filtered = []
        
        for candidate in candidates:
            # ì§€ì—­ í•„í„°
            if region and region not in candidate.region:
                continue
                
            # ì¹´í…Œê³ ë¦¬ í•„í„°
            if place_class is not None and candidate.place_class != place_class:
                continue
                
            filtered.append(candidate)
            
        return filtered
    
    def calculate_final_score(self, result: SearchResult) -> float:
        """ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        return (self.alpha * result.vector_score + 
                self.beta * result.tag_score + 
                self.gamma * result.popularity_score)
    
    def apply_mmr(self, results: List[SearchResult], lambda_param: float = 0.5) -> List[SearchResult]:
        """MMR (Maximal Marginal Relevance) ì ìš©ìœ¼ë¡œ ë‹¤ì–‘ì„± í™•ë³´"""
        if len(results) <= 1:
            return results
            
        selected = [results[0]]
        remaining = results[1:]
        
        while remaining and len(selected) < len(results):
            mmr_scores = []
            
            for candidate in remaining:
                # ê´€ë ¨ì„± ì ìˆ˜ (ê¸°ì¡´ ì„ íƒëœ í•­ëª©ë“¤ê³¼ì˜ í‰ê·  ìœ ì‚¬ë„)
                relevance = candidate.final_score
                
                # ë‹¤ì–‘ì„± ì ìˆ˜ (ê¸°ì¡´ ì„ íƒëœ í•­ëª©ë“¤ê³¼ì˜ ìµœì†Œ ìœ ì‚¬ë„)
                diversity = min(
                    self.calculate_tag_score(candidate.tags, selected_item.tags)
                    for selected_item in selected
                )
                
                # MMR ì ìˆ˜
                mmr_score = lambda_param * relevance + (1 - lambda_param) * diversity
                mmr_scores.append((mmr_score, candidate))
            
            # ìµœê³  MMR ì ìˆ˜ë¥¼ ê°€ì§„ í•­ëª© ì„ íƒ
            best_score, best_candidate = max(mmr_scores, key=lambda x: x[0])
            selected.append(best_candidate)
            remaining.remove(best_candidate)
        
        return selected
    
    def search_and_rerank(self, user_input: str, user_tags: List[str] = None, 
                         region: str = "", place_class: int = None, 
                         page: int = 1, page_size: int = 20) -> Dict:
        """ë©”ì¸ ê²€ìƒ‰ ë° ì¬ë­í‚¹ í•¨ìˆ˜"""
        
        # 1. ì‚¬ìš©ì ì…ë ¥ì—ì„œ íƒœê·¸ ìë™ ì¶”ì¶œ (ì‚¬ìš©ìê°€ íƒœê·¸ë¥¼ ì œê³µí•˜ì§€ ì•Šì€ ê²½ìš°)
        if not user_tags:
            extracted = self.extract_tags_with_llm(user_input)
            user_tags = extracted.get("tags", [])
            if not region and extracted.get("region"):
                region = extracted.get("region")
        
        print(f"Extracted tags: {user_tags}")
        print(f"Extracted region: {region}")
        
        # 2. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ í›„ë³´ ì¶”ì¶œ
        try:
            query_embedding = self.get_clova_embedding(user_input)
            distances, indices = self.vector_search(query_embedding, self.initial_k)
        except Exception as e:
            print(f"Vector search failed: {e}")
            return {"results": [], "total": 0, "page": page, "has_next": False}
        
        # 3. í›„ë³´ ë°ì´í„° êµ¬ì„±
        candidates = []
        for i, (distance, idx) in enumerate(zip(distances, indices)):
            if idx >= len(self.metadata):
                continue
                
            row = self.metadata.iloc[idx]
            
            # íƒœê·¸ ì •ë³´ ì¶”ì¶œ
            place_tags = []
            for col in ['tag1', 'tag2', 'tag3', 'tag4', 'tag5']:
                if col in row and pd.notna(row[col]) and str(row[col]).strip():
                    place_tags.append(str(row[col]).strip())
            
            # ë²¡í„° ì ìˆ˜ (ê±°ë¦¬ë¥¼ ì ìˆ˜ë¡œ ë³€í™˜)
            vector_score = 1.0 / (1.0 + distance)
            
            # íƒœê·¸ ì ìˆ˜
            tag_score = self.calculate_tag_score(user_tags, place_tags)
            
            # ì¸ê¸°ë„ ì ìˆ˜
            popularity_score = self.calculate_popularity_score(row)
            
            candidate = SearchResult(
                place_id=i,
                name=str(row.get('ëª…ì¹­', '')),
                address=str(row.get('ì£¼ì†Œ', '')),
                region=str(row.get('ì§€ì—­', '')),
                overview=str(row.get('ê°œìš”', '')),
                tags=place_tags,
                place_class=int(row.get('place_class', 0)),
                lat=float(row.get('lat', 0)),
                lng=float(row.get('lng', 0)),
                vector_score=vector_score,
                tag_score=tag_score,
                popularity_score=popularity_score,
                final_score=0.0
            )
            
            candidates.append(candidate)
        
        # 4. í•˜ë“œ í•„í„° ì ìš©
        candidates = self.apply_hard_filters(candidates, region, place_class)
        
        # 5. ìµœì¢… ì ìˆ˜ ê³„ì‚°
        for candidate in candidates:
            candidate.final_score = self.calculate_final_score(candidate)
        
        # 6. ì ìˆ˜ìˆœ ì •ë ¬
        candidates.sort(key=lambda x: x.final_score, reverse=True)
        
        # 7. ìµœì†Œ ì ìˆ˜ í•„í„°ë§ (ë„ˆë¬´ ë‚®ì€ ì ìˆ˜ëŠ” ì œì™¸)
        min_score_threshold = 0.05  # ë” ì—„ê²©í•œ ì„ê³„ê°’
        candidates = [c for c in candidates if c.final_score >= min_score_threshold]
        
        # íƒœê·¸ ë§¤ì¹­ì´ ìˆëŠ” ê²°ê³¼ë§Œ ìš°ì„  ì„ íƒ
        candidates_with_tags = [c for c in candidates if c.tag_score > 0]
        candidates_without_tags = [c for c in candidates if c.tag_score == 0]
        
        # íƒœê·¸ ë§¤ì¹­ì´ ìˆëŠ” ê²°ê³¼ë¥¼ ë¨¼ì €, ê·¸ ë‹¤ìŒì— ë²¡í„° ì ìˆ˜ë§Œ ë†’ì€ ê²°ê³¼ë¥¼ ì¶”ê°€
        candidates = candidates_with_tags + candidates_without_tags[:50]  # ë²¡í„° ì ìˆ˜ë§Œ ë†’ì€ ê²°ê³¼ëŠ” ìµœëŒ€ 50ê°œë§Œ
        
        # 8. MMR ì ìš© (ë‹¤ì–‘ì„± í™•ë³´)
        candidates = self.apply_mmr(candidates)
        
        # 9. í˜ì´ì§€ë„¤ì´ì…˜
        total = len(candidates)
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        page_results = candidates[start_idx:end_idx]
        
        print(f"Total candidates after filtering: {total}")
        print(f"Page {page} results: {len(page_results)}")
        
        return {
            "results": page_results,
            "total": total,
            "page": page,
            "has_next": end_idx < total,
            "total_pages": math.ceil(total / page_size),
            "user_tags": user_tags,
            "extracted_region": region
        }

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
recommendation_engine = AdvancedRecommendationEngine()

# ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜
def get_recommendations(user_input: str, user_tags: List[str] = None, 
                       region: str = "", place_class: int = None,
                       page: int = 1, page_size: int = 20) -> Dict:
    """ê¸°ì¡´ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í•¨ìˆ˜"""
    return recommendation_engine.search_and_rerank(
        user_input, user_tags, region, place_class, page, page_size
    )

# ê¸°ì¡´ app ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
class GraphState(TypedDict, total=False):
    user_input: str
    ì§€ì—­: str
    ê°ì •: str
    í™œë™: str
    íƒœê·¸: str
    ë³´ì¶©_ì§ˆë¬¸: str
    recommendations: List[str]
    ì¶”ì²œ_ì¥ì†Œëª…: List[str]
    ì¥ì†Œ_íƒœê·¸ë§µ: dict

def extract_info(state: GraphState) -> GraphState:
    """ê¸°ì¡´ í˜¸í™˜ì„± í•¨ìˆ˜"""
    extracted = recommendation_engine.extract_tags_with_llm(state["user_input"])
    
    # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    region = extracted.get("region", "")
    activity = extracted.get("activity", "")
    tags = ", ".join(extracted.get("tags", []))
    
    need_followup = not region or not activity
    
    return {
        **state,
        "ì§€ì—­": region,
        "í™œë™": activity,
        "íƒœê·¸": tags,
        "ë³´ì¶©_ì§ˆë¬¸": "ë” êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”." if need_followup else "",
        "need_followup": need_followup
    }

def recommend_places(state: GraphState) -> GraphState:
    """ê¸°ì¡´ í˜¸í™˜ì„± í•¨ìˆ˜"""
    results = recommendation_engine.search_and_rerank(
        state["user_input"], 
        page=1, 
        page_size=3
    )
    
    # ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    recommendations = []
    ì¶”ì²œ_ì¥ì†Œëª… = []
    ì¥ì†Œ_íƒœê·¸ë§µ = {}
    
    for i, result in enumerate(results["results"][:3], 1):
        place_name = result.name
        ì¶”ì²œ_ì¥ì†Œëª….append(place_name)
        ì¥ì†Œ_íƒœê·¸ë§µ[place_name] = result.tags
        
        recommendations.append(f"{i}. **[{place_name}]**")
        recommendations.append(f"- ì´ìœ : {result.overview[:100]}...")
    
    return {
        **state,
        "recommendations": recommendations,
        "ì¶”ì²œ_ì¥ì†Œëª…": ì¶”ì²œ_ì¥ì†Œëª…,
        "ì¥ì†Œ_íƒœê·¸ë§µ": ì¥ì†Œ_íƒœê·¸ë§µ
    }

# ê¸°ì¡´ StateGraph êµ¬ì¡° ìœ ì§€
from langchain_core.runnables import RunnableLambda
from langgraph.graph import StateGraph

builder = StateGraph(GraphState)
builder.add_node("extract_info", RunnableLambda(extract_info))
builder.add_node("recommend", RunnableLambda(recommend_places))

def should_recommend(state: GraphState):
    return not state.get("need_followup", False)

builder.set_entry_point("extract_info")
builder.add_conditional_edges(
    "extract_info",
    should_recommend,
    {
        True: "recommend",
        False: "extract_info"
    }
)
builder.set_finish_point("recommend")
builder.set_finish_point("extract_info")

app = builder.compile()

if __name__ == "__main__":
    print("=== TripTailor ê³ ê¸‰ ì¶”ì²œ ì‹œìŠ¤í…œ ===")
    print("ì˜ˆì‹œ: 'ê°•ì›ë„ì—ì„œ ë‹¨í’ êµ¬ê²½í•˜ë©´ì„œ ì¡°ìš©íˆ íë§í•  ìˆ˜ ìˆëŠ” ê³³ ì¶”ì²œí•´ì¤˜'")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        try:
            user_input = input("ì—¬í–‰ ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            if not user_input:
                print("ì…ë ¥ì„ ë‹¤ì‹œ í•´ì£¼ì„¸ìš”.\n")
                continue

            print("\nì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...\n")
            
            # ìƒˆë¡œìš´ ì—”ì§„ ì‚¬ìš©
            results = recommendation_engine.search_and_rerank(user_input, page=1, page_size=5)
            
            if results["results"]:
                print(f"ğŸ¯ ì¶”ì²œ ê²°ê³¼ (ì´ {results['total']}ê°œ)")
                print(f"ğŸ“ ì¶”ì¶œëœ ì§€ì—­: {results['extracted_region'] or 'ì§€ì •ë˜ì§€ ì•ŠìŒ'}")
                print(f"ğŸ·ï¸  ì¶”ì¶œëœ íƒœê·¸: {', '.join(results['user_tags'])}")
                print()
                
                for i, result in enumerate(results["results"], 1):
                    print(f"{i}. **{result.name}**")
                    print(f"   ğŸ“ {result.address}")
                    print(f"   ğŸ·ï¸  {', '.join(result.tags) if result.tags else 'íƒœê·¸ ì—†ìŒ'}")
                    print(f"   ğŸ“Š ìµœì¢…ì ìˆ˜: {result.final_score:.3f}")
                    print(f"   ğŸ’¡ {result.overview[:100]}...")
                    print()
            else:
                print("ğŸ˜” ì¶”ì²œ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                print("ë” êµ¬ì²´ì ì¸ ì¡°ê±´ì„ ì…ë ¥í•´ë³´ì„¸ìš”.")

            print("=" * 50 + "\n")

        except KeyboardInterrupt:
            print("\n\nì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")
