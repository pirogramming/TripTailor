import os
import json
import requests
import uuid
import numpy as np
import faiss
import pandas as pd
from typing import List, TypedDict
from dotenv import load_dotenv

from langchain_core.runnables import RunnableLambda
from langchain_core.prompts import PromptTemplate
from langchain_naver import ChatClovaX
from langgraph.graph import StateGraph

# FAISS ì¸ë±ìŠ¤ ë° ë©”íƒ€ë°ì´í„° ë¡œë“œ
_index = None
_metadata = None

def _load_faiss_and_meta():
    global _index, _metadata
    if _index is not None and _metadata is not None:
        return _index, _metadata
    try:
        import faiss, pandas as pd
        _index = faiss.read_index(os.getenv("FAISS_INDEX_PATH", "triptailor_cosine_v2.index"))
        _metadata = pd.read_csv(os.getenv("FAISS_META_PATH", "triptailor_full_metadata.csv")).fillna("")
        return _index, _metadata
    except Exception as e:
        print(f"[warn] FAISS/CSV load failed: {e}")
        return None, None

# DB ê²€ìƒ‰ ë„ìš°ë¯¸
def search_top_k_from_db(qvec, k=10):
    # â† í•¨ìˆ˜ ë‚´ë¶€ë¡œ ì˜®ê¸°ê¸° (Djangoê°€ ì¤€ë¹„ëœ ë’¤ ì„í¬íŠ¸)
    from apps.places.models import Place
    from apps.tags.models import Tag
    from pgvector.django import L2Distance, CosineDistance, MaxInnerProduct

    metric = os.getenv("PGVECTOR_METRIC", "l2")
    if metric == "cosine":
        distance = CosineDistance("embedding", qvec)
    elif metric == "ip":
        distance = MaxInnerProduct("embedding", qvec)
    else:
        distance = L2Distance("embedding", qvec)

    qs = (Place.objects.exclude(embedding=None)
        .annotate(dist=distance)
        .order_by("dist")
        .prefetch_related("tags")[:k])

    return [{
        "ëª…ì¹­": p.name,
        "ì£¼ì†Œ": p.address or "",
        "ê°œìš”": p.overview or "",
        "tags": [t.name for t in p.tags.all()],
    } for p in qs]


# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# LLM ì„¤ì •
llm = ChatClovaX(
    model="HCX-005",
    temperature=0,
)

# ì •ë³´ ì¶”ì¶œ í”„ë¡¬í”„íŠ¸
extraction_prompt = PromptTemplate.from_template(
    """
    ë‹¤ìŒ ì‚¬ìš©ìì˜ ë¬¸ì¥ì—ì„œ ì—¬í–‰ ê´€ë ¨ ì •ë³´ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•´ì¤˜.
    ë¬¸ì¥: "{input}"

    ì¶”ì¶œ í•­ëª©:
    - ì§€ì—­: ì—¬í–‰í•˜ê³  ì‹¶ì€ ì§€ì—­ (ì—†ìœ¼ë©´ "ì—†ìŒ")
    - ê°ì •: ì›í•˜ëŠ” ë¶„ìœ„ê¸°ë‚˜ ê°ì • (ì˜ˆ: ì¡°ìš©í•œ, íë§, í™œê¸°ì°¬ ë“±, ì—†ìœ¼ë©´ "ì—†ìŒ")
    - í™œë™: í•˜ê³  ì‹¶ì€ í™œë™ (ì˜ˆ: ë‹¨í’ êµ¬ê²½, ì‚°ì±… ë“±, ì—†ìœ¼ë©´ "ì—†ìŒ")

    ìœ„ 3ê°œ ì¤‘ í•˜ë‚˜ë¼ë„ "ì—†ìŒ"ì´ë©´ ë³´ì¶© ì§ˆë¬¸ì„ ì¶”ê°€í•´ì¤˜.
    ëª¨ë‘ ìˆë‹¤ë©´ ë³´ì¶© ì§ˆë¬¸ì€ ë¹ˆ ë¬¸ìì—´ë¡œ í•´ì¤˜.

    ì¶œë ¥ í˜•ì‹ (JSON):
    {{
    "ì§€ì—­": "...",
    "ê°ì •": "...",
    "í™œë™": "...",
    "ë³´ì¶© ì§ˆë¬¸": "..."
    }}
    """
)

# ì¶”ì²œ í”„ë¡¬í”„íŠ¸
recommendation_prompt = PromptTemplate.from_template(
    """
    ì•„ë˜ 'ì—¬í–‰ì§€ ë¦¬ìŠ¤íŠ¸' ì¤‘ì—ì„œë§Œ ê³ ë¥´ê³ , ì‚¬ìš©ì ì¡°ê±´ì— ë§ëŠ” ì—¬í–‰ì§€ **ì •í™•íˆ 3ê³³**ì„ ì¶”ì²œí•˜ë¼.
    ë¦¬ìŠ¤íŠ¸ì— ì—†ëŠ” ì¥ì†Œëª…ì€ ì ˆëŒ€ ì“°ì§€ ë§ˆë¼.

    # ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì¤€ìˆ˜)
    1. **[ì—¬í–‰ì§€ëª…]**
    - ì´ìœ : ë‘ ë¬¸ì¥, 80~150ì. ì²« ë¬¸ì¥ì€ ì‚¬ìš©ì ì¡°ê±´ê³¼ì˜ ì í•©ì„±(ì§€ì—­/ê°ì •/í™œë™ ì—°ê²°), 
            ë‘ ë²ˆì§¸ ë¬¸ì¥ì€ í•´ë‹¹ ì¥ì†Œì˜ ì£¼ìš” íŠ¹ì§•ê³¼ ë§¤ë ¥ì„ ì„¤ëª….
    - êµ¬ì²´ì ì¸ íŒ: ë°©ë¬¸ ì‹œê°„ëŒ€, ë™ì„ , ì¤€ë¹„ë¬¼, ê³„ì ˆë³„ ì¶”ì²œ í™œë™ ë“± ì‹¤ì§ˆì ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” íŒì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ì œê³µ.

    2. **[ì—¬í–‰ì§€ëª…]**
    - ì´ìœ : ë‘ ë¬¸ì¥, 80~150ì.
    - êµ¬ì²´ì ì¸ íŒ: 1~2ë¬¸ì¥.

    3. **[ì—¬í–‰ì§€ëª…]**
    - ì´ìœ : ë‘ ë¬¸ì¥, 80~150ì.
    - êµ¬ì²´ì ì¸ íŒ: 1~2ë¬¸ì¥.

    # ì‘ì„± ê·œì¹™
    - íƒœê·¸(ì˜ˆ: #íë§, #ì•¼ê²½ ë“±)ëŠ” ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ.
    - í•´ì‹œíƒœê·¸, ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´, ì´ëª¨ì§€, ì¥ì‹ ë¬¸ìë¥¼ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ.
    - ì¥ì†Œëª…ì€ ë°˜ë“œì‹œ ì—¬í–‰ì§€ ë¦¬ìŠ¤íŠ¸ì— ìˆëŠ” ê²ƒë§Œ ì‚¬ìš©.
    - ì„¤ëª…ì€ ìì—°ìŠ¤ëŸ½ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•˜ë˜, ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ë‚˜ ë°˜ë³µì€ í”¼í•  ê²ƒ.

    # ì‚¬ìš©ì ì •ë³´
    - ì§€ì—­: {location}
    - ê°ì •: {emotion}
    - í™œë™: {activity}
    - íƒœê·¸ ì¡°ê±´: {tags} (ì°¸ê³ ìš©ì´ë©°, ê²°ê³¼ ë¬¸ì¥ì— ì§ì ‘ ì“°ì§€ ë§ ê²ƒ)

    # ì—¬í–‰ì§€ ë¦¬ìŠ¤íŠ¸
    {trip_spot_list}
    """
)




extraction_chain = extraction_prompt | llm
recommendation_chain = recommendation_prompt | llm

class GraphState(TypedDict, total=False):
    user_input: str
    ì§€ì—­: str
    ê°ì •: str
    í™œë™: str
    íƒœê·¸: str
    ë³´ì¶©_ì§ˆë¬¸: str
    recommendations: List[str]
    ì¶”ì²œ_ì¥ì†Œëª…: List[str]
    ì¥ì†Œ_íƒœê·¸ë§µ: dict

def get_clova_embedding(text: str, api_key: str) -> List[float]:
    url = "https://clovastudio.stream.ntruss.com/v1/api-tools/embedding/v2"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json",
        "X-NCP-CLOVASTUDIO-REQUEST-ID": str(uuid.uuid4())
    }
    response = requests.post(url, headers=headers, json={"text": text})
    response.raise_for_status()
    return response.json()["result"]["embedding"]

def extract_info(state: GraphState) -> GraphState:
    raw = extraction_chain.invoke({"input": state["user_input"]})
    response_text = getattr(raw, "content", str(raw))
    try:
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}') + 1
        json_str = response_text[start_idx:end_idx]
        parsed = json.loads(json_str)
    except:
        parsed = {"ì§€ì—­": "ì—†ìŒ", "ê°ì •": "ì—†ìŒ", "í™œë™": "ì—†ìŒ", "ë³´ì¶© ì§ˆë¬¸": "ì–´ë””ì—ì„œ ì—¬í–‰í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?"}

    # ì¶”ì²œ ì¡°ê±´ì´ ëª¨ë‘ ìˆì„ ë•Œë§Œ recommendë¡œ ë„˜ê¹€
    need_followup = (
        parsed.get("ì§€ì—­", "ì—†ìŒ") == "ì—†ìŒ" or
        parsed.get("ê°ì •", "ì—†ìŒ") == "ì—†ìŒ" or
        parsed.get("í™œë™", "ì—†ìŒ") == "ì—†ìŒ"
    )
    return {
        **state,
        "ì§€ì—­": parsed.get("ì§€ì—­", ""),
        "ê°ì •": parsed.get("ê°ì •", ""),
        "í™œë™": parsed.get("í™œë™", ""),
        "ë³´ì¶©_ì§ˆë¬¸": parsed.get("ë³´ì¶© ì§ˆë¬¸", ""),
        "need_followup": need_followup
    }

def recommend_places(state: GraphState) -> GraphState:
    # 1) ì¿¼ë¦¬ ì„ë² ë”©
    embedding = get_clova_embedding(state["user_input"], os.getenv("CLOVASTUDIO_API_KEY"))
    qvec = list(map(float, embedding))  # list[float]

    # 2) DBì—ì„œ top-k ì‹œë„
    try:
        rows = search_top_k_from_db(qvec, k=10)
    except Exception as e:
        print(f"[warn] DB retrieval failed, fallback to FAISS: {e}")
        rows = None

    if rows is None:
        index, metadata = _load_faiss_and_meta()
        if index is None or metadata is None:
            raise RuntimeError("DB ê²€ìƒ‰ ì‹¤íŒ¨í–ˆê³  FAISS ë¦¬ì†ŒìŠ¤ë„ ì—†ìŠµë‹ˆë‹¤.")
        emb_np = np.ascontiguousarray([qvec], dtype=np.float32)
        D, I = index.search(emb_np, k=10)
        top_k = metadata.iloc[I[0]]
        rows = [{
            "ëª…ì¹­": str(row["ëª…ì¹­"]),
            "ì£¼ì†Œ": str(row["ì£¼ì†Œ"]),
            "ê°œìš”": str(row["ê°œìš”"]),
            "tags": [str(row.get(c, "")).strip() for c in ["tag1","tag2","tag3","tag4","tag5"] if str(row.get(c, "")).strip()],
        } for _, row in top_k.iterrows()]

    # 4) LLM ì…ë ¥ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±
    trip_spot_list = "\n".join(
        f"- {r['ëª…ì¹­']} ({r['ì£¼ì†Œ']}): {r['ê°œìš”']} [íƒœê·¸: {', '.join(r['tags'])}]"
        for r in rows
    )

    combined_tags = ", ".join(sorted({t for r in rows for t in r["tags"] if t}))

    rec = recommendation_chain.invoke({
        "trip_spot_list": trip_spot_list,
        "location": state["ì§€ì—­"],
        "emotion": state["ê°ì •"],
        "activity": state["í™œë™"],
        "tags": combined_tags
    })

    response_text = getattr(rec, "content", str(rec))
    raw_lines = [ln.strip() for ln in response_text.splitlines() if ln.strip()]

    recommended_places = []
    for line in raw_lines:
        if line.strip().startswith(("1.", "2.", "3.")):
            start = line.find("**[") + 3
            end = line.find("]**")
            place_name = line[start:end] if start != -1 and end != -1 else ""
            if place_name:
                recommended_places.append(place_name)

    # 5) íƒœê·¸ ë§µ (DB/FAISS ê³µí†µ)
    place_info_map = {r["ëª…ì¹­"]: r["tags"] for r in rows}

    return {
        **state,
        "recommendations": raw_lines,
        "íƒœê·¸": combined_tags,
        "ì¶”ì²œ_ì¥ì†Œëª…": recommended_places,
        "ì¥ì†Œ_íƒœê·¸ë§µ": place_info_map
    }


# StateGraphì—ì„œ ì¡°ê±´ ë¶„ê¸° ì¶”ê°€
builder = StateGraph(GraphState)
builder.add_node("extract_info", RunnableLambda(extract_info))
builder.add_node("recommend", RunnableLambda(recommend_places))

# ë¶„ê¸°: ë³´ì¶© ì§ˆë¬¸ì´ í•„ìš”í•˜ë©´ recommendë¡œ ê°€ì§€ ì•ŠìŒ
def should_recommend(state: GraphState):
    return not state.get("need_followup", False)

builder.set_entry_point("extract_info")
builder.add_conditional_edges(
    "extract_info",
    should_recommend,
    {
        True: "recommend",
        False: "extract_info"  # ë³´ì¶© ì§ˆë¬¸ë§Œ ë°˜í™˜í•˜ê³  ì¢…ë£Œ
    }
)
builder.set_finish_point("recommend")
builder.set_finish_point("extract_info")
app = builder.compile()

if __name__ == "__main__":
    print("=== TripTailor ì—¬í–‰ì§€ ì¶”ì²œ ì‹œìŠ¤í…œ ===")
    print("ì˜ˆì‹œ: 'ê°•ì›ë„ì—ì„œ ë‹¨í’ êµ¬ê²½í•˜ë©´ì„œ ì¡°ìš©íˆ íë§í•  ìˆ˜ ìˆëŠ” ê³³ ì¶”ì²œí•´ì¤˜'")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit'ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

    while True:
        try:
            user_input = input("ì—¬í–‰ ì¡°ê±´ì„ ì…ë ¥í•˜ì„¸ìš”: ").strip()
            if user_input.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
                print("ì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
                break
            if not user_input:
                print("ì…ë ¥ì„ ë‹¤ì‹œ í•´ì£¼ì„¸ìš”.\n")
                continue

            state = {"user_input": user_input}
            print("\nì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤...\n")
            result = app.invoke(state)

            if result.get("ë³´ì¶©_ì§ˆë¬¸"):
                print("ğŸ¤” ë³´ì¶© ì§ˆë¬¸:", result["ë³´ì¶©_ì§ˆë¬¸"])
                followup = input("â†’ ë³´ì¶© ë‹µë³€: ").strip()
                full_input = result["user_input"] + " " + followup
                state = {"user_input": full_input}
                print("\në³´ì™„ëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì‹œ ì¶”ì²œí•©ë‹ˆë‹¤...\n")
                result = app.invoke(state)

            print("ğŸ“‹ ì¶”ì¶œëœ ì •ë³´:")
            for key in ["ì§€ì—­", "ê°ì •", "í™œë™"]:
                if value := result.get(key):
                    print(f"  - {key}: {value}")

            print("\nğŸ¯ [ì¶”ì²œ ê²°ê³¼]")
            i = 0
            while i < len(result["recommendations"]):
                line = result["recommendations"][i].strip()
                if line.startswith(("1.", "2.", "3.")):
                    print(line)
                    if i + 1 < len(result["recommendations"]):
                        reason_line = result["recommendations"][i + 1].strip()
                        if reason_line.startswith("- ì´ìœ :"):
                            print(reason_line)

                    place_name = line[line.find("**[") + 3:line.find("]**")].strip()
                    tag_map = result.get("ì¥ì†Œ_íƒœê·¸ë§µ", {})
                    best_match = next((name for name in tag_map if place_name in name or name in place_name), None)
                    if best_match:
                        tags = tag_map[best_match]
                        print(f"- íƒœê·¸: {', '.join(tags) if tags else '(íƒœê·¸ ì—†ìŒ)'}")
                    else:
                        print("- íƒœê·¸: (FAISS ê²°ê³¼ ë‚´ì—ì„œ ì¥ì†Œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤)")

                    print()
                i += 1

            print("=" * 50 + "\n")

        except KeyboardInterrupt:
            print("\n\nì¶”ì²œ ì‹œìŠ¤í…œì„ ì¢…ë£Œí•©ë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")
            break
        except Exception as e:
            print(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
            print("ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\n")